{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8bfb54a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "###create a folder or env named etl\n",
    "## add __init__.py (from etl import extract,transform,load)\n",
    "##Extract\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "def consolidate_csv():\n",
    "    \n",
    "    new_folder =Path(\"extracts/new\")\n",
    "    csv_files =[item for item in new_folder.glob(\"*.csv\")]\n",
    "    \n",
    "    if csv_files:\n",
    "        dfs = []\n",
    "        \n",
    "        for csv_file in csv_files:\n",
    "            dfs.append(pd.read_csv(csv_file))\n",
    "        \n",
    "        staging_table = pd.concat(dfs,ignore_index= True)\n",
    "        staging_table['Order Date'] = pd.to_datetime(['Order date'])\n",
    "        return staging_table\n",
    "    else:\n",
    "        print(\"There are no files in folder.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff3054bc",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'pandas' has no attribute 'Dataframe'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#tranform\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtransform\u001b[39m(staging_table:pd\u001b[38;5;241m.\u001b[39mDataframe):\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;66;03m#create a copy of staging table\u001b[39;00m\n\u001b[0;32m      6\u001b[0m     transformed_table \u001b[38;5;241m=\u001b[39m staging_table\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;66;03m#Rename columns\u001b[39;00m\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;66;03m#extract yy,mm,dd from order date\u001b[39;00m\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;66;03m#extract street , city ,state,zip from address\u001b[39;00m\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;66;03m#rearrange columns and remove duplicates\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\__init__.py:264\u001b[0m, in \u001b[0;36m__getattr__\u001b[1;34m(name)\u001b[0m\n\u001b[0;32m    260\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01marrays\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msparse\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SparseArray \u001b[38;5;28;01mas\u001b[39;00m _SparseArray\n\u001b[0;32m    262\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _SparseArray\n\u001b[1;32m--> 264\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmodule \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpandas\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'pandas' has no attribute 'Dataframe'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def transform(staging_table: pd.DataFrame):\n",
    "    # Create a copy of the staging table\n",
    "    transformed_table = staging_table.copy()\n",
    "\n",
    "    # Rename columns\n",
    "    transformed_table.rename(columns={\n",
    "        'order_date': 'order_date',\n",
    "        'address': 'address'\n",
    "    }, inplace=True)\n",
    "\n",
    "    # Extract yy, mm, dd from the order date\n",
    "    transformed_table['order_year'] = pd.to_datetime(transformed_table['order_date']).dt.year\n",
    "    transformed_table['order_month'] = pd.to_datetime(transformed_table['order_date']).dt.month\n",
    "    transformed_table['order_day'] = pd.to_datetime(transformed_table['order_date']).dt.day\n",
    "\n",
    "    # Extract street, city, state, zip from the address\n",
    "    transformed_table[['street', 'city', 'state', 'zip']] = transformed_table['address'].str.split(',', expand=True)\n",
    "\n",
    "    # Rearrange columns\n",
    "    transformed_table = transformed_table[['order_date', 'order_year', 'order_month', 'order_day', 'street', 'city', 'state', 'zip']]\n",
    "\n",
    "    # Remove duplicates\n",
    "    transformed_table.drop_duplicates(inplace=True)\n",
    "\n",
    "    return transformed_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "322fc767",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unmatched ')' (2350569705.py, line 12)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn[3], line 12\u001b[1;36m\u001b[0m\n\u001b[1;33m    env = load_dotenv)\u001b[0m\n\u001b[1;37m                     ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unmatched ')'\n"
     ]
    }
   ],
   "source": [
    "#load\n",
    "# Import required packages\n",
    "import os\n",
    "import pandas as pd\n",
    "from dotenv import load_dotenv\n",
    "from sqlalchemy import create_engine,Engine\n",
    "from sqlalchemy.engine import URL\n",
    "\n",
    "\n",
    "@task\n",
    "def get_engine():\n",
    "    # Load environment variables\n",
    "    env = load_dotenv)\n",
    "\n",
    "    #Get values from env file\n",
    "    HOST = os.getenv(\"HOST\")\n",
    "    DB = os.getenv(\"DB\")\n",
    "    USER = os.getenv(\"USER\")\n",
    "    PASS = os.getenv(\"PASS\")\n",
    "\n",
    "    #Define connection string\n",
    "    connection_string + URL.CREATE(\n",
    "        drivername = \"mssql+pyodbc\",\n",
    "        host=HOST,\n",
    "        database=DB,\n",
    "        username=USER,\n",
    "        password=PASS,\n",
    "        query={\"driver\":\"ODBC Driver 17 for SQL Server\"}\n",
    "    )\n",
    "    \n",
    "    #Create Engine\n",
    "    engine = create_engine(connection_string)\n",
    "    \n",
    "    return engine\n",
    "\n",
    "\n",
    "def load_to_db(transformed_table:pd.DataFrame,table_name:str):\n",
    "    \"\"\" Load transfromed_table to database \n",
    "    \"\"\"\n",
    "    transformed_table.to_sql(table_name,con=get_engine(),if_exists=\"append\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57dd2490",
   "metadata": {},
   "outputs": [],
   "source": [
    "#main pipeline outside etl package create a file named main.py\n",
    "from etl import extract,transform,load\n",
    "\n",
    "if __name__ ==\"__main__\":\n",
    "    \n",
    "    staging_table = extract.consolidated_csv()\n",
    "    transfromed_table = transform.transform(staging_table)\n",
    "    load.load_to_db(transformed_table,\"name of the table\")\n",
    "    \n",
    "    ##USAGE\n",
    "    \n",
    "##in TERMINAL TYPE THIS python .\\main.py"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
