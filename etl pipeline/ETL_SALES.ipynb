{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a250c6e",
   "metadata": {},
   "source": [
    "# EXTRACT CSV,EXCEL, DATABASE SALES DATA\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "21cd1981",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libraries needed\n",
    "import psycopg2\n",
    "import glob\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "\n",
    "    \n",
    "#funtion extracting from excel\n",
    "def consolidated_sales_excel():\n",
    "    #excel file path\n",
    "    excel_file_path = r'C:\\Users\\\\Public\\Sales_January_April_2019.xlsx'\n",
    "    \n",
    "    sales_excel = pd.read_excel(excel_file_path, sheet_name=None)\n",
    "    \n",
    "    excel_df = pd.concat(sales_excel.values(),  ignore_index=True)\n",
    "        \n",
    "    return excel_df\n",
    "\n",
    "#funtion extracting from csv\n",
    "def consolidated_sales_csv():\n",
    "    new_folder = r'C:\\Users\\Public\\sales_csv'\n",
    "    csv_files = glob.glob(f'{new_folder}/*.csv')\n",
    "    \n",
    "    if csv_files:\n",
    "        csv_df=[]\n",
    "    \n",
    "        for csv_file in csv_files:\n",
    "            csv_df.append(pd.read_csv(csv_file))\n",
    "            \n",
    "            csv_dfs = pd.concat(csv_df,ignore_index= True)\n",
    "        \n",
    "        return csv_dfs\n",
    "    else:\n",
    "        print(\"There is no file in folder.\")\n",
    "        \n",
    "#funtion extracting from database\n",
    "def consolidated_sales_db():\n",
    "    # PostgreSQL connection\n",
    "    pg_username = 'postgres'\n",
    "    pg_password = 'posgres1234'\n",
    "    pg_host = 'localhost'\n",
    "    pg_port = '5432'\n",
    "    pg_database = 'sales_sep_dec_2019'\n",
    "    \n",
    "    \n",
    "\n",
    "    # Define PostgreSQL connection string\n",
    "    pg_connection_string = f'postgresql://{pg_username}:{pg_password}@{pg_host}:{pg_port}/{pg_database}'\n",
    "\n",
    "    # Create SQLAlchemy engine\n",
    "    engine = create_engine(pg_connection_string)\n",
    "\n",
    "    # SQL query to extract data from PostgreSQL table\n",
    "    sql_query = 'SELECT * FROM sales_db'\n",
    "\n",
    "    # Use pandas to read the SQL query result into a data frame\n",
    "    pg_df = pd.read_sql(sql_query, engine)\n",
    "    \n",
    "    return pg_df\n",
    "\n",
    "\n",
    "\n",
    "def consolidated_data():\n",
    "    result_excel = consolidated_sales_excel()\n",
    "    result_csv = consolidated_sales_csv()\n",
    "    result_db = consolidated_sales_db()\n",
    "\n",
    "    # Concatenate the DataFrames vertically\n",
    "    consolidated_result = pd.concat([result_excel, result_csv], ignore_index=True)\n",
    "\n",
    "    #renaming columns\n",
    "    consolidated_result = consolidated_result.rename(columns={'Order ID': 'order_id',\n",
    "                                                              'Product': 'product',\n",
    "                                                              'Quantity Ordered':'quantity_ordered',\n",
    "                                                              'Price Each':'price_each',\n",
    "                                                              'Order Date':'order_date',\n",
    "                                                              'Purchase Address':'address'})\n",
    "    consolidated_result = pd.concat([consolidated_result, result_db], ignore_index=True)\n",
    "    \n",
    "    return consolidated_result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd1853c3",
   "metadata": {},
   "source": [
    "# transform consolidated SALES DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1fc3163f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_sales(staging_table : pd.DataFrame):\n",
    "    transformed_table = staging_table.copy()\n",
    "    \n",
    "    transformed_table = transformed_table.dropna(how='any')\n",
    "\n",
    "    # Filter out rows where 'Order Date' is not a valid date\n",
    "    transformed_table = transformed_table[transformed_table['order_date'] != 'Order Date']\n",
    "\n",
    "    # Convert 'order_id' to numeric, replace non-numeric values with NaN\n",
    "    transformed_table['order_id'] = pd.to_numeric(transformed_table['order_id'], errors='coerce')\n",
    "    transformed_table = transformed_table.dropna(subset =['order_id'])\n",
    "    transformed_table['order_id'] = transformed_table['order_id'].astype(int)\n",
    "\n",
    "    # Ensure 'product' column is of string type\n",
    "    transformed_table['product'] = transformed_table['product'].astype(str)\n",
    "\n",
    "    # Convert 'quantity_ordered' to numeric, replace non-numeric values with NaN\n",
    "    transformed_table['quantity_ordered'] = pd.to_numeric(transformed_table['quantity_ordered'], errors='coerce')\n",
    "\n",
    "    # Convert 'price_each' to numeric, replace non-numeric values with NaN\n",
    "    transformed_table['price_each'] = pd.to_numeric(transformed_table['price_each'], errors='coerce')\n",
    "\n",
    "    # Ensure 'purchase_address' column is of string type\n",
    "    transformed_table['address'] = transformed_table['address'].astype(str)\n",
    "    \n",
    "    # Convert 'order_date' to datetime\n",
    "    transformed_table['order_date'] = pd.to_datetime(transformed_table['order_date'], errors='coerce')\n",
    "    \n",
    "    # Extract yy, mm, dd from the order date\n",
    "    transformed_table['order_year'] = pd.to_datetime(transformed_table['order_date']).dt.year\n",
    "    transformed_table['order_month'] = pd.to_datetime(transformed_table['order_date']).dt.strftime('%b')\n",
    "    transformed_table['order_day'] = pd.to_datetime(transformed_table['order_date']).dt.day\n",
    "\n",
    "    address_split = transformed_table['address'].str.split(', ', expand=True)\n",
    "    transformed_table['street'] = address_split[0]\n",
    "    transformed_table['city'] = address_split[1]\n",
    "    transformed_table['state'] = address_split[2]\n",
    "    \n",
    "    zip_split = transformed_table['state'].str.split(' ', expand=True)\n",
    "    transformed_table['state'] = zip_split[0]\n",
    "    transformed_table['zip'] = zip_split[1]\n",
    "    \n",
    "    transformed_table['country'] = \"United States\"\n",
    "\n",
    "    # Rearrange columns\n",
    "    transformed_table = transformed_table[['order_id',\n",
    "                                           'order_year', \n",
    "                                           'order_month', \n",
    "                                           'order_day',\n",
    "                                           'product', \n",
    "                                           'quantity_ordered',\n",
    "                                           'price_each',\n",
    "                                           'street', \n",
    "                                           'city',\n",
    "                                           'state',\n",
    "                                           'zip',\n",
    "                                           'country']]\n",
    "\n",
    "    # Remove duplicates\n",
    "    transformed_table.drop_duplicates(subset=['order_id'], inplace=True)\n",
    "    \n",
    "    return transformed_table\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a6f621bf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 185686 entries, 0 to 186849\n",
      "Data columns (total 12 columns):\n",
      " #   Column            Non-Null Count   Dtype  \n",
      "---  ------            --------------   -----  \n",
      " 0   order_id          185686 non-null  int32  \n",
      " 1   order_year        185686 non-null  int64  \n",
      " 2   order_month       185686 non-null  object \n",
      " 3   order_day         185686 non-null  int64  \n",
      " 4   product           185686 non-null  object \n",
      " 5   quantity_ordered  185686 non-null  int64  \n",
      " 6   price_each        185686 non-null  float64\n",
      " 7   street            185686 non-null  object \n",
      " 8   city              185686 non-null  object \n",
      " 9   state             185686 non-null  object \n",
      " 10  zip               185686 non-null  object \n",
      " 11  country           185686 non-null  object \n",
      "dtypes: float64(1), int32(1), int64(3), object(7)\n",
      "memory usage: 17.7+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "staging_table = consolidated_data()\n",
    "transformed_table = transform_sales(staging_table)\n",
    "print(transformed_table.info())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1653e49a",
   "metadata": {},
   "source": [
    "# LOAD transformed_table TO DATABASE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "014dce5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sqlalchemy import create_engine,exc\n",
    "\n",
    "pg_username = 'postgres'\n",
    "pg_password = 'posgres1234'\n",
    "pg_host = 'localhost'\n",
    "pg_port = '5432'\n",
    "pg_database = 'sales_sep_dec_2019'\n",
    "\n",
    "def get_engine():\n",
    "    pg_connection_string = f'postgresql://{pg_username}:{pg_password}@{pg_host}:{pg_port}/{pg_database}'\n",
    "    engine = create_engine(pg_connection_string)\n",
    "    return engine\n",
    "\n",
    "def load_to_db(transformed_table: pd.DataFrame, table_name: str):\n",
    "    engine = get_engine()\n",
    "    \n",
    "    try:\n",
    "        transformed_table.to_sql(table_name, con=engine, if_exists=\"append\", index=False)\n",
    "        print(f'sales data successfully loaded into {table_name} table.')\n",
    "    except exc.SQLAlchemyError as e:\n",
    "        print(f'Error loading data into {table_name} table: {e}')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c2d03856",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sales data successfully loaded into annual_sales_2019 table.\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "staging_table = consolidated_data()\n",
    "transformed_table = transform_sales(staging_table)\n",
    "load = load_to_db(transformed_table, table_name='annual_sales_2019')\n",
    "print(load)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e30439f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
